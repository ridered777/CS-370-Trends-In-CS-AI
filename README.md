# CS-370-Trends-In-CS-AI

Briefly explain the work you did:

For this project, the actual deep q-learning implementation was mostly done for us. The architecture for the training of the model needed to be input, and for that I used a simple series to generate the experience from the inputs and then applied the model to the history of the agent. Lastly, I calculated the loss and win-rate. The output calculations were provided and most of the input definitions were provided so it was largely a game of lining up the right inputs to create the right data and outputs, and constructing it in a way that is both with the industry best practices as well as logically sound. Beyond that, there was some code written by me to generate the win history as that wasn’t provided either.


Connect your learning:

Computer Scientists solve problems at their core. Problem solving and decomposition will always be an important skill in society and one that should always matter. Computer Scientist happen to showcase this via slightly less than usual methods and whether it be a software design document or a piece of code, that happens to be what the status quo requires currently. However, it could always change and adapt in the future as it does every day with new languages and new technologies emerging.

I attempt to decompose and break a problem down into components when tackling it. This approach to the problem seems to net the most successful results at the highest quality for the least amount of time invested which is always the end-goal.

The ethical responsibilities to an end user or an organization are going to be based in the same principles everyone (should) be incorporating every day in their lives. If we were all good to each other (no malicious intent), didn’t steal from each other (no unauthorized data usage/sales), respected each others’ privacy (no hidden data mining), and did our best (provide that which was paid for such as an employer to an employee) the world would have a pretty strong ethical starting place.
